{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# We will use the official tokenization script created by the Google team\n",
        "! pip install -q -U \"tensorflow-text==2.11.*\"\n",
        "! pip install -q tf-models-official==2.11.0 #For optimizer"
      ],
      "metadata": {
        "id": "_5K92vWbzjv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "id": "15n9P_FhHQwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data"
      ],
      "metadata": {
        "id": "i1w07oERIgrd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08gP9Su1w2d6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "\n",
        "# import tokenization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading data in pandas dataframe\n",
        "\n",
        "data_train = pd.read_json('./data/train.jsonl', lines=True)\n",
        "data_valid = pd.read_json('./data/dev.jsonl', lines=True)\n",
        "data_test = pd.read_json('./data/test.jsonl', lines=True)"
      ],
      "metadata": {
        "id": "wDvDqdIgxuVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "LDds4Gorx05b",
        "outputId": "7c1cf3db-af6b-47ef-9308-53ce2060337c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label     label_text\n",
              "0  a stirring , funny and finally transporting re...      4  very positive\n",
              "1  apparently reassembled from the cutting-room f...      1       negative\n",
              "2  they presume their audience wo n't sit still f...      1       negative\n",
              "3  the entire movie is filled with deja vu moments .      2        neutral\n",
              "4  this is a visually stunning rumination on love...      3       positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-524c09d6-3588-4d5a-995f-18777dce8ce7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>label_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>4</td>\n",
              "      <td>very positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the entire movie is filled with deja vu moments .</td>\n",
              "      <td>2</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>3</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-524c09d6-3588-4d5a-995f-18777dce8ce7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-524c09d6-3588-4d5a-995f-18777dce8ce7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-524c09d6-3588-4d5a-995f-18777dce8ce7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train['label'].value_counts().plot(kind='bar')\n",
        "print(data_train['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Gsj4CKp7nE9Q",
        "outputId": "e3d5d6dc-eec1-41da-90b6-7284f1122e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3    2322\n",
            "1    2218\n",
            "2    1624\n",
            "4    1288\n",
            "0    1092\n",
            "Name: label, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing using Tokenizer"
      ],
      "metadata": {
        "id": "E0C7FqXpGCdQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "aChWJtzaIltp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\""
      ],
      "metadata": {
        "id": "DeCjHc9xH4wY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ],
      "metadata": {
        "id": "06qZw00OHxLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_test = ['this is such an amazing movie!']\n",
        "print(data_train['text'][0])\n",
        "text_preprocessed = bert_preprocess_model(text_test) #by default it truncates each vector at 128\n",
        "print(text_preprocessed)\n",
        "# print(text_preprocessed[\"input_word_ids\"])\n",
        "#Testing\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kmq1tGrpH-PM",
        "outputId": "6a825ca7-5a0f-4979-f222-df0eeda528b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a stirring , funny and finally transporting re-imagining of beauty and the beast and 1930s horror films\n",
            "{'input_mask': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
            "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "      dtype=int32)>, 'input_type_ids': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
            "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "      dtype=int32)>, 'input_word_ids': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
            "array([[ 101, 2023, 2003, 2107, 2019, 6429, 3185,  999,  102,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0]], dtype=int32)>}\n",
            "Keys       : ['input_mask', 'input_type_ids', 'input_word_ids']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comments = data_train['text'].values\n",
        "labels = data_train['label'].values\n"
      ],
      "metadata": {
        "id": "ZchGrSIVrDwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use RandomOverSampler to balance the classes\n",
        "\n",
        "# oversampler = RandomOverSampler(random_state=42)\n",
        "# comments_resampled, labels_resampled = oversampler.fit_resample(comments.reshape(-1, 1), labels)\n",
        "\n",
        "# # count the number of samples in each class after oversampling\n",
        "# class_counts = pd.Series(labels_resampled).value_counts()\n",
        "# print(\"Class counts after oversampling:\\n\", class_counts)\n"
      ],
      "metadata": {
        "id": "TRQtiBSwoXre",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8170ebd9-9e33-4b7c-c0ff-9422bc6e49d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts after oversampling:\n",
            " 4    2322\n",
            "1    2322\n",
            "2    2322\n",
            "3    2322\n",
            "0    2322\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_comments = []\n",
        "# for comment in comments_resampled:\n",
        "#   train_comments.append(comment[0])"
      ],
      "metadata": {
        "id": "w4mLyZlLsfqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 5\n",
        "\n",
        "#One hot encode since we have more than 2 classes\n",
        "def one_hot_encode(dataset):\n",
        "    num_samples = len(dataset)\n",
        "    # labels = dataset['label']\n",
        "    encoding = np.zeros((num_samples, NUM_CLASSES))\n",
        "    \n",
        "    for i in range(num_samples):\n",
        "        label_value = dataset[i]\n",
        "        encoding[i][label_value] = 1\n",
        "        \n",
        "    return encoding\n",
        "    \n",
        "y_train = one_hot_encode(data_train['label'])\n",
        "y_valid = one_hot_encode(data_valid['label'])\n",
        "y_test = one_hot_encode(data_test['label'])\n",
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt5OTNb3yiZo",
        "outputId": "ebbd0697-6c82-475a-d7b2-377466226869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(comments):\n",
        "  return bert_preprocess_model(comments)"
      ],
      "metadata": {
        "id": "75zcA3qaZxSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = preprocess(data_train['text'].tolist())\n",
        "valid_train = preprocess(data_valid['text'].tolist())\n",
        "test_train = preprocess(data_test['text'].tolist())"
      ],
      "metadata": {
        "id": "tfNg-aygLRHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input Pipeline"
      ],
      "metadata": {
        "id": "B0LmyQsbNYfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((train_dataset['input_word_ids'], train_dataset['input_mask'], train_dataset['input_type_ids'], y_train))\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((valid_train['input_word_ids'], valid_train['input_mask'], valid_train['input_type_ids'], y_valid))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_train['input_word_ids'], test_train['input_mask'], test_train['input_type_ids'], y_test))"
      ],
      "metadata": {
        "id": "_ZAaJuFaWXyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_features(input_word_ids, input_type_ids, input_mask,label):\n",
        "    return ({\"input_word_ids\":input_word_ids, \"input_type_ids\":input_type_ids, 'input_mask': input_mask}, label) #(input, output) reformat\n"
      ],
      "metadata": {
        "id": "ygCQsJqLij7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Input pipeline\n",
        "def prepare_dataset(dataset, batch_size=64):\n",
        "    dataset = dataset.map(map_features)\n",
        "    dataset = dataset.shuffle(10000)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "8Jew2C7Mi4GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = prepare_dataset(train_ds)\n",
        "valid_ds = prepare_dataset(valid_ds)\n",
        "test_ds = prepare_dataset(test_ds)\n",
        "train_ds.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfsQDumzi7_u",
        "outputId": "24b5772f-4fcf-4331-e05e-ff0de4bf8b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset element_spec=({'input_word_ids': TensorSpec(shape=(None, 128), dtype=tf.int32, name=None), 'input_type_ids': TensorSpec(shape=(None, 128), dtype=tf.int32, name=None), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int32, name=None)}, TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Bert Model"
      ],
      "metadata": {
        "id": "qRydn3KbNVrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
        "# bert_layer = hub.KerasLayer(model_url)\n",
        "\n",
        "# bert_results = bert_layer([text_preprocessed['input_ids'],text_preprocessed['input_masks']])\n",
        "\n",
        "# print(f'Loaded BERT: {model_url}')\n",
        "# print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "# print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "# print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "# print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "metadata": {
        "id": "Kj8K0kuvNaoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier_model(seq_length=128):\n",
        "  input_ids = tf.keras.layers.Input(shape=(seq_length,), dtype=tf.int32, name='input_word_ids')\n",
        "  input_mask = tf.keras.layers.Input(shape=(seq_length,), dtype=tf.int32, name='input_mask')\n",
        "  input_type_ids = tf.keras.layers.Input(shape=(seq_length,), dtype=tf.int32, name='input_type_ids')\n",
        "  \n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  embeddings = encoder({'input_word_ids': input_ids, 'input_mask': input_mask, 'input_type_ids': input_type_ids})['pooled_output']\n",
        "\n",
        "  x = tf.keras.layers.Dense(128, activation='relu')(embeddings)\n",
        "  x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "\n",
        "  y = tf.keras.layers.Dense(5, activation='softmax', name='classifier')(embeddings)\n",
        "\n",
        "  return tf.keras.Model(inputs=[input_ids, input_mask, input_type_ids], outputs=y)\n"
      ],
      "metadata": {
        "id": "_lczTJhKylbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = build_classifier_model()"
      ],
      "metadata": {
        "id": "zUMkkY6b0ZPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZqyLkAr1CjC",
        "outputId": "d2c9b392-7010-455e-824a-800d6746c826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_mask (InputLayer)        [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " input_type_ids (InputLayer)    [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " input_word_ids (InputLayer)    [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'sequence_output':  28763649    ['input_mask[0][0]',             \n",
            "                                 (None, 128, 512),                'input_type_ids[0][0]',         \n",
            "                                 'default': (None,                'input_word_ids[0][0]']         \n",
            "                                512),                                                             \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 512),                                               \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 512)}                                                       \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 5)            2565        ['BERT_encoder[0][5]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,766,214\n",
            "Trainable params: 28,766,213\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "NCSjJDDRUqHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')\n",
        "metrics = tf.metrics.CategoricalAccuracy()"
      ],
      "metadata": {
        "id": "2UmWZ0QFUsZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 3e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ],
      "metadata": {
        "id": "l4ZYcri9VMUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)"
      ],
      "metadata": {
        "id": "oWuoQl_IV7m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training model with {tfhub_handle_encoder}')\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
        "\n",
        "history = classifier_model.fit(x=train_ds,\n",
        "                               validation_data=valid_ds,\n",
        "                               epochs=epochs,\n",
        "                               callbacks=[checkpoint, earlystopping],\n",
        "                               batch_size=64,\n",
        "                               verbose=1\n",
        "                               )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyDCvCd-WD9g",
        "outputId": "87202edd-7e91-4439-cce8-d6d64b34b34c"
      },
      "execution_count": 168,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Epoch 1/5\n",
            "134/134 [==============================] - ETA: 0s - loss: 1.5911 - categorical_accuracy: 0.2707 "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "134/134 [==============================] - 2583s 19s/step - loss: 1.5911 - categorical_accuracy: 0.2707 - val_loss: 1.5649 - val_categorical_accuracy: 0.2598\n",
            "Epoch 2/5\n",
            "134/134 [==============================] - ETA: 0s - loss: 1.5396 - categorical_accuracy: 0.3010 "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134/134 [==============================] - 2521s 19s/step - loss: 1.5396 - categorical_accuracy: 0.3010 - val_loss: 1.4383 - val_categorical_accuracy: 0.3542\n",
            "Epoch 3/5\n",
            "134/134 [==============================] - ETA: 0s - loss: 1.4369 - categorical_accuracy: 0.3654 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r134/134 [==============================] - 2572s 19s/step - loss: 1.4369 - categorical_accuracy: 0.3654 - val_loss: 1.4108 - val_categorical_accuracy: 0.3724\n",
            "Epoch 4/5\n",
            "134/134 [==============================] - ETA: 0s - loss: 1.3881 - categorical_accuracy: 0.3914 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r134/134 [==============================] - 2509s 19s/step - loss: 1.3881 - categorical_accuracy: 0.3914 - val_loss: 1.3629 - val_categorical_accuracy: 0.4105\n",
            "Epoch 5/5\n",
            "134/134 [==============================] - ETA: 0s - loss: 1.3540 - categorical_accuracy: 0.4109 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r134/134 [==============================] - 2508s 19s/step - loss: 1.3540 - categorical_accuracy: 0.4109 - val_loss: 1.3518 - val_categorical_accuracy: 0.4024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.save('sentiment_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahQXQkz9s7TR",
        "outputId": "a28b8f31-9513-40fc-859a-8c13507138ff"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 124). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = classifier_model.evaluate(test_ds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r_7sBE6ttoN",
        "outputId": "c1728d17-fe18-44b3-f69a-d1d22352c285"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 191s 5s/step - loss: 1.3598 - categorical_accuracy: 0.4054\n"
          ]
        }
      ]
    }
  ]
}